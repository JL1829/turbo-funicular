{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some note of Big-O Notation\n",
    "> Some Algorithm basic that Data Scientist easy to skip. \n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Algorithm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It begins with a story\n",
    "***\n",
    "\n",
    "I always recall that when I was kid, my math teacher love to ask a question: \n",
    "\n",
    "- **Who can tell me the answer of adding 1 to 100**?\n",
    "\n",
    "Some student started to calculate: $1+2+3+4+5+6+7+......$. \n",
    "\n",
    "The one who always get No.1 in class tell the answer in a very short time: **It's $5050$**\n",
    "\n",
    "Teacher ask: \"How you do that?\"\n",
    "\n",
    "He said: \"Well, $1+100$ is $101$, and $2+99$ is $101$, there's total $50$ of $101$, so that answer is $50 \\times 101$, which is $5050$. \n",
    "\n",
    "The smart boy definitely not me, I am the one who record this story, but it do inspire me the extended question: **What if we are not adding 1 to 100, but adding 1 to `n`?**\n",
    "\n",
    "Let's solve this question by writing a function to sum from 1 to $n$. That's simple: \n",
    "\n",
    "**Python Solution 1**\n",
    "\n",
    "```python\n",
    "def summation(n):\n",
    "    result = 0\n",
    "    for i in range(1, n+1):\n",
    "        result += i\n",
    "    \n",
    "    return result\n",
    "\n",
    "array = [1, 2, 3, 4, 5]\n",
    "summation(5) == sum(array) #expected True\n",
    "```\n",
    "\n",
    "**Python Solution 2**\n",
    "\n",
    "```python\n",
    "def summation(n):\n",
    "    return n * (n + 1) // 2\n",
    "\n",
    "array = [1, 2, 3, 4, 5]\n",
    "summation(5) == sum(array) #expected True\n",
    "```\n",
    "\n",
    "Can you tell me which algorithm is better? and Why?\n",
    "\n",
    "Some will say: \"I think the Solution 1 is better, because the *Zen of Python* said *Readability Count*, the *Solution 1* is very easy to understand at the first glance, you know what it's doing at the very begnning. \"\n",
    "\n",
    "Some will say: \"I think the Solution 2 is better, because it always one step to get the answer.\"\n",
    "\n",
    "Well, that's close, let's do the step by step analysis to compare this two solution: \n",
    "\n",
    "**Solution 1**:\n",
    "\n",
    "Let's say the $n$ is $5$:\n",
    "- Step 1: initialized `result = 0`\n",
    "- Step 2: Start the loop from `i = 1`, then `result = 1 + 0 = 1`\n",
    "- Step 2: In the Loop: now `i = 2`, execute: `result = 1 + 2 = 3`\n",
    "- Step 3: In the Loop: now `i = 3`, execute: `result = 3 + 3 = 6`\n",
    "- Step 4: In the Loop: now `i = 4`, execute: `result = 6 + 4 = 10`\n",
    "- Step 5: In the Loop: now `i = 5`, execute: `result = 10 + 5 = 15`\n",
    "- Step 6: return the `result` value. \n",
    "\n",
    "**Solution 2**:\n",
    "\n",
    "Let's say the $n$ is $5$:\n",
    "- Step 1: return the value: $\\frac{5 \\times (5 + 1)}{2} = 15$\n",
    "\n",
    "Ok, in the first solution, the *Steps* will grows when the $n$ grows, let's say the $n$ is millions, then the function need to execuate millions time to get the answer. In contrast, no matter how big is the $n$, in the second solution, there will be always one time execuation to get the answers, so no matter in a slower computer, or a super fast computer, **Solution 2** will be always faster than the **Solution 1**\n",
    "\n",
    "Above analysis it just qualitative, what science need is precise, so what's the quantitative analysis for it to precisely identify and analyse the algorithm? \n",
    "\n",
    "# Introducing the Big-O Notation\n",
    "***\n",
    "When trying to characterize an algorithm’s efficiency in terms of execution time, independent of any particular program or computer, it is important to quantify the number of operations or steps that the algorithm will require. If each of these steps is considered to be a basic unit of computation, then the execution time for an algorithm can be expressed as the number of steps required to solve the problem. Deciding on an appropriate basic unit of computation can be a complicated problem and will depend on how the algorithm is implemented.\n",
    "\n",
    "In the summation functions given above, it makes sense to use the number of terms in the summation to denote the size of the problem. We can then say that the sum of the first 100,000 integers is a bigger instance of the summation problem than the sum of the first 1,000. Because of this, it might seem reasonable that the time required to solve the larger case would be greater than for the smaller case. Our goal then is to show how the algorithm’s execution time changes with respect to the size of the problem.\n",
    "\n",
    "Computer scientists prefer to take this analysis technique one step further. It turns out that the exact number of operations is not as important as determining the most dominant part of the $T(n)$ function. In other words, as the problem gets larger, some portion of the $T(n)$ function tends to overpower the rest. This dominant term is what, in the end, is used for comparison. The **Order of Magnitude** function describes the part of $T(n)$ that increases the fastest as the value of $n$ increases. Order of magnitude is often called **Big-O** Notation(for **Order**) and written as $O(f(n))$. It provides a useful approximation to the actual number of steps in the computation. The function $f(n)$ rovides a simple representation of the dominant part of the original $T(n)$. \n",
    "\n",
    "## Common Functions for Big-O:\n",
    "***\n",
    "$n$ --> The size of the input\n",
    "\n",
    "- Constant runtime(Time Complexity): $O(1)$\n",
    "- Logarithmic runtime(Time Complexity): $O(\\log (n))$\n",
    "- Linear runtime(Time Complexity): $O(n)$\n",
    "- LinearLogarithmic runtime(Time Complexity): $O(n\\log (n))$\n",
    "- Quadric runtime(Time Complexity): $O(n^2)$\n",
    "- Cubic runtime(Time Complexity): $O(n^3)$\n",
    "- Exponential runtime(Time Complexity): $O(b^n), b > 1$\n",
    "- Factorial runtime(Time Complexity): $O(n!)$\n",
    "\n",
    "If we plot the graph of each run time: \n",
    "![img](https://runestone.academy/runestone/books/published/pythonds3/_images/newplot.png)\n",
    "\n",
    "So if we visit back our begins story. What do you think the _Time Complexity_ of **Solution 1** and **Solution 2**? Comment below. \n",
    "\n",
    "\n",
    "## Big-O Notation Rules: \n",
    "***\n",
    "\n",
    "### **Rule 1: Different Steps get added**\n",
    "\n",
    "**Example**\n",
    "\n",
    "```python\n",
    "def doSomething():\n",
    "    doStep(a) #O(a)\n",
    "    doStep(b) #O(b)\n",
    "    \n",
    "    return\n",
    "```\n",
    "\n",
    "So for the above example, the Time Complexity should be: $O(a+b)$\n",
    "***\n",
    "\n",
    "### **Rule 2: Drop Constants**\n",
    "\n",
    "**Example**\n",
    "\n",
    "**One**\n",
    "```python\n",
    "def minMax(array):\n",
    "    minimum, maximum = None, None\n",
    "    for i in array:\n",
    "        minimum = min(i, minimum)\n",
    "    for i in array:\n",
    "        maximum = max(i, maximum)\n",
    "    \n",
    "    return minimun, maximum\n",
    "```\n",
    "\n",
    "**Two**\n",
    "```python\n",
    "def minMax(array):\n",
    "    minimum, maximum = None, None\n",
    "    for i in array:\n",
    "        minimum = min(i, minimum)\n",
    "        maximum = max(i, maximum)\n",
    "    \n",
    "    return minimum, maximum\n",
    "```\n",
    "\n",
    "The above TWO functions do the same thing, return the `min` and `max` value from an `array`, but the **One** is first find the `min`, and then find the `max`, so the actual steps is `2n`, while the **Two** is finding the `min`, `max` concurrently, so the actual steps is `n`. \n",
    "\n",
    "You may say the **One** time complexity is `O(2n)` and **Two** time complexity is `O(n)`, the actual answer is both of them time complexity is `O(n)`, because when the `n` approach to `inf`, the constant `2` will be less significant till can be ignored, so this is the **Rule 2: Drop the constant**\n",
    "***\n",
    "\n",
    "### **Rule 3: Different Inputs --> Different Variables**\n",
    "\n",
    "**Example**\n",
    "\n",
    "```python\n",
    "def intersectionSize(arrayA, arrayB):\n",
    "    count = 0\n",
    "    for a in arrayA:\n",
    "        for b in arrayB:\n",
    "            if a == b:\n",
    "                count += 1\n",
    "    \n",
    "    return count\n",
    "```\n",
    "\n",
    "Well, this function have `loop` in the `loop`, we can easily identify it as $O(n^2)$ of time complexity, but actually is False, let's ask a simple question, what is the `n` means? well, we may say `n` is the input size of the array, ok, then which array? `arrayA` or `arrayB`? since this is different variables, and the `n` repersent different variable input size, here we should describe the time complexity as: \n",
    "- $O(a \\times b)$\n",
    "***\n",
    "\n",
    "### **Rule 4: Drop the non-dominant terms**\n",
    "\n",
    "**Example**\n",
    "\n",
    "```python\n",
    "\n",
    "def IdontKnowWhatIamDoing(array:list):\n",
    "    maximun = None\n",
    "    \n",
    "    # O(n) Time complexity\n",
    "    for i in array:\n",
    "        maximun = max(a, maximum)\n",
    "    print(maximum)\n",
    "    \n",
    "    # O(n^2) Time complexity\n",
    "    for a in array:\n",
    "        for b in array:\n",
    "            print(a, b)\n",
    "```\n",
    "\n",
    "We can see from above function `IdontKnowWhatIamDoing`, the 1st part's time complexity is $O(n)$, and the 2nd parts' time complexity is $O(n^2)$, does it mean the total time complexity is $O(n + n^2)$?\n",
    "\n",
    "Well, let's do some simulation: \n",
    "\n",
    "- if `n = 1`, there's $O(1 + 1^2 = 2)$\n",
    "- if `n = 2`, there's $O(2 + 2^2 = 5)$\n",
    "- if `n = 10`, there's $O(10 + 10^2 = 110)$\n",
    "- if `n = 10,000`, there's $O(10,000 + 10,000^2 = ???)$\n",
    "- if `n = 100,000`, there's $O(100,000 + 100,000^2)$\n",
    "\n",
    "What pattern do you found? when the `n` grows, the $n^2$ have more dominance, and the $n$ part become less significant, in the Big-O Notation, we are not doing the details computation, Big-O notation is the unified way to describe an algroithm's time complexity and space complexity(may discuss next post), so we just need to know the donimant term that impact the run time the most. so here we drop the non-dominant term, the time complexity is: \n",
    "\n",
    "- $O(n^2)$\n",
    "\n",
    "***\n",
    "\n",
    "### Some Exercises?\n",
    "\n",
    "We have finished the Rules of Big-O Notation, how about a small exercises? it can be solved based on the info above: \n",
    "![pic](https://github.com/JL1829/turbo-funicular/raw/master/images/Screenshot%202020-10-06%20at%2016.49.15.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
