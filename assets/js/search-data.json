{
  
    
        "post0": {
            "title": "Cost-Sensitive Decision Trees for Imbalanced Classification",
            "content": "Overview . This tutorial divided into 4 pars: . Imbalanced classfication dataset | Decision Trees for Imbalanced classfication | Weighted Decision Tree with Scikit-Learn | Grid Search Weighted Decision Trees | . Imbalanced classfication dataset . we use the make_classification()function to define a synthetic imbalanced two-class classfication dataset. We generate 10,000 examples with an approximate 1:100 minority to majority class ratio . # import the packages from collections import Counter from sklearn.datasets import make_classification from matplotlib import pyplot as plt import numpy as np . # generate dataset X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=3) # examinate the info of X and y print(f&#39;The type of X is {type(X)}&#39;) print(f&#39;The type of y is {type(y)}&#39;) print(&#39; n&#39;) print(f&#39;The size of X is {X.shape}&#39;) print(f&#39;The size of y is {y.shape}&#39;) . The type of X is &lt;class &#39;numpy.ndarray&#39;&gt; The type of y is &lt;class &#39;numpy.ndarray&#39;&gt; The size of X is (10000, 2) The size of y is (10000,) . # summarize class distribution counter = Counter(y) print(counter) . Counter({0: 9900, 1: 100}) . # scatter plot of examples by class label for label, _ in counter.items(): row_ix = np.where(y == label)[0] plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) plt.legend() plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Fit it with standard decision tree model . A decision tree can be defined using the DecisionTreeClassifier class in the scikit-learn library . # import packages from sklearn.model_selection import cross_val_score from sklearn.model_selection import RepeatedStratifiedKFold from sklearn.tree import DecisionTreeClassifier # define model model = DecisionTreeClassifier() . # define evaluation procedure cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) # evaluate model score = cross_val_score(model, X, y, scoring=&#39;roc_auc&#39;, cv=cv, n_jobs=-1) # summarize performance print(f&#39;Mean ROC AUC: {np.mean(score):.3f}&#39;) . Mean ROC AUC: 0.734 . The model performance is achieving a ROC AUC above 0.5 which is 0.734 . This model can be the baseline for comparision for any modification performed to the standard decision tree algorithm . Decision Trees for Imbalanced Classification . The decision tree algorithm is also known as Classification and Regression Trees and involves growing a tree to classify examples from the training dataset. . The tree can be thought to divide the training dataset, where examples progress down the decision points of the tree to arrive in the leaves of the tree and are assigned a class label. . The tree is constructed by splitting the training dataset using values for variables in the dataset. At each point, the split in the data that results in the purest (least mixed) groups of examples is chosen in a greedy manner. . Here, purity means a clean separation of examples into groups where a group of examples of all 0 or all 1 class is the purest, and a 50-50 mixture of both classes is the least pure. Purity is most commonly calculated using Gini impurity, although it can also be calculated using entropy . The calculation of a purity measure involves calculating the probability of an example of a given class being misclassified by a split. Calculating these probabilities involves summing the number of examples in each class within each group. . The splitting criterion can be updated to not only take the purity of the split into account, but also be weighted by the importance of each class. . This can be achieved by replacing the count of examples in each group by a weighted sum, where the coefficient is provided to weight the sum. . Larger weight is assigned to the class with more importance, and a smaller weight is assigned to a class with less importance. . Small Weight: Less importance, lower impact on node purity | Large Weight: More importance, higher impact on node purity | . A small weight can be assigned to the majority class, which has the effect of improving (lowering) the purity score of a node that may otherwise look less well sorted. In turn, this may allow more examples from the majority class to be classified for the minority class, better accommodating those examples in the minority class. . As such, this modification of the decision tree algorithm is referred to as a weighted decision tree, a class-weighted decision tree, or a cost-sensitive decision tree. . Modification of the split point calculation is the most common, although there has been a lot of research into a range of other modifications of the decision tree construction algorithm to better accommodate a class imbalance. . Weighted Decision Tree with Scikit-learn . The scikit-learn Python machine learning library provides an implementation of the decision tree algorithm that supports class weighting. . The DecisionTreeClassifier class provides the class_weight argument that can be specified as a model hyperparameter. The class_weight is a dictionary that defines each class label (e.g. 0 and 1) and the weighting to apply in the calculation of group pruity for splits in the decision tree when fitting the model . For example: . # define model weights = {0:1.0, 1:1.0} model = DecisionTreeClassifier(class_weight=weights) . The class weighting can be defined multiple ways, for example: . Domain Expertise: determined by talking to subject matter experts | Tuning: determined by hyperparameter search such as GirdSearch | Huristic: spcified using a general best practice | . A best practice for using the class weighting is to use the inverse of the class distribution present in the training dataset. . For example, the class distribution of the test dataset is a 1:100 ratio for the minority class to the majority class. The invert of this ratio could be used with 1 for the majority class and 100 for the minority class. . for example: . # define model weights = {0:1.0, 1:100.0} model = DecisionTreeClassifier(class_weight=weights) . We might also define the same ratio using fractions and achieve the same results . # define model weights = {0:0.01, 1:1.0} model = DecisionTreeClassifier(class_weight=weights) . Or also can be defined by pre-loaded attributes: python model = DecisionTreeClassifier(class_weight=&#39;balanced&#39;) . Detail about class_weight in DecisionTreeClassifier class . **class_weightdict, list of dict or “balanced”, default=None** . Weights associated with classes in the form {class_label: weight}. If None, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y. . Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}]. . The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)) . For multi-output, the weights of each column of y will be multiplied. . Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified. . # decision tree with class weight on an imbalanced classification dataset model = DecisionTreeClassifier(class_weight=&#39;balanced&#39;) cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) scores = cross_val_score(model, X, y, scoring=&#39;roc_auc&#39;, cv=cv, n_jobs=-1) . # print out performance print(f&#39;The model ROC AUC mean is: {np.mean(scores):.3f}&#39;) . The model ROC AUC mean is: 0.749 . Ok, very well, the performance just a little bit imporved, from 0.734 to 0.749 . Grid Search Weighted Decision Tree . Using a class weighting that is the inverse ratio of the training data is just a heuristic. . It is possible that better performance can be achieved with a different class weighting, and this too will depend on the choice of performance metric used to evaluate the model. . In this section, we will grid search a range of different class weightings for the weighted decision tree and discover which results in the best ROC AUC score. . We will try the following weightings for class 0 and 1: . Class 0: 100, Class 1: 1 | Class 0: 10, Class 1: 1 | Class 0: 1, Class 1: 1 | Class 0: 1, Class 1: 10 | Class 0: 1, Class 1: 100 | . This can be defined as grid search parameter for the GridSearchCV class as follow: . # define grid balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}] param_grid = dict(class_weight=balance) . # define grid balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}] param_grid = dict(class_weight=balance) print(param_grid) . {&#39;class_weight&#39;: [{0: 100, 1: 1}, {0: 10, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 10}, {0: 1, 1: 100}]} . from sklearn.model_selection import GridSearchCV # define evaluation procedure cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) # define model model = DecisionTreeClassifier() # define grid search grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring=&#39;roc_auc&#39;, verbose=1) # fit the GridSearch grid_result = grid.fit(X, y) . Fitting 30 folds for each of 5 candidates, totalling 150 fits [Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers. [Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 0.4s finished . # report the best configuration print(f&#39;Best {grid_result.best_score_} using {grid_result.best_params_}&#39;) . Best 0.750925925925926 using {&#39;class_weight&#39;: {0: 1, 1: 10}} . # report all configurations means = grid_result.cv_results_[&#39;mean_test_score&#39;] stds = grid_result.cv_results_[&#39;std_test_score&#39;] params = grid_result.cv_results_[&#39;params&#39;] for mean, stdev, param in zip(means, stds, params): print(&quot;%f (%f) with: %r&quot; % (mean, stdev, param)) . 0.740556 (0.071391) with: {&#39;class_weight&#39;: {0: 100, 1: 1}} 0.735539 (0.070241) with: {&#39;class_weight&#39;: {0: 10, 1: 1}} 0.735707 (0.068985) with: {&#39;class_weight&#39;: {0: 1, 1: 1}} 0.750926 (0.071732) with: {&#39;class_weight&#39;: {0: 1, 1: 10}} 0.746212 (0.075781) with: {&#39;class_weight&#39;: {0: 1, 1: 100}} . Very well, fine turning the Class_weight hyperparameter, we have 0.01 performance imporve . Further Reading . Paper . An instance-weighting Method To Induce Cost-sensitive Tree, 2002 | . Books . Learning from Imbalanced Datasets, 2018 | Imbalanced Learning: Foundations, Algorithms, and Applications, 2013. | . APIs . sklearn.utils.class_weight.compute_class_weight | sklearn.tree.DecisionTreeClassifier | sklearn.model_selection.GridSearchCV | .",
            "url": "https://jl1829.github.io/turbo-funicular/jupyter/2020/02/26/Decision_Tree_Imbalance.html",
            "relUrl": "/jupyter/2020/02/26/Decision_Tree_Imbalance.html",
            "date": " • Feb 26, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jl1829.github.io/turbo-funicular/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jl1829.github.io/turbo-funicular/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi and welcome to my blog, I am Johnny.Lu, staying in the “Fine” city called Singapore(joke), currently I am the Lead Consulting Engineer(Data Science, Machine Learning)in Allied Telesis, a Japanese pioneer company in digital communication. . Experiences . Allied Telesis . Lead Consulting Engineerr, (Machine Learning, Data Science). Singapore, Jun/2017 – Current . Leading Data Science and System Engineer team to develop products that measurably and efficiently improve sales and top-line growth. | Interfacing with customers to receive valuable product feedback. | Driving strategy and vision for products by translating research, customer insights, and data discovery into innovative solutions for customers. | Actively collaborating with global IT, Architectures, Infrastructure, and Sales teams to deploy products. | Develop End-to-End Data Science, Machine Learning Project using: MySQL, Scikit-Learn, NumPy, Pandas, PySpark, TensorFlow 2, Keras | LightGBM, XGBoost, SpaCy, NLTK | . | . | Regional System Engineer Singapore, May/2016 – Jun/2017 . Response to business development, including leads generating, roadshow/seminar conducting, solution designing, quoting/bidding, solution deploying, and after sales servicing. | Promote Allied Telesis SDN, Service Cloud solution; initiative in the region, managing the technical team to provide high reliability services. | Managing key account, provide advisory of the option for new technology adoption. | . | . NETGEAR Inc. . Regional System Engineer Singapore, Jun/2013 – May/2016 Act as a constant performer, teaming with Regional Sales Director, perform annually business growth. | Provide consultation service to downstream partner &amp; end user, including basic infra network design and deployment, integration with virtualization, customized solution for individual customers. | . | Regional System Engineer Guangzhou, China, Nov/2012 – Oct/2013 Design, develop and carry out technical solutions | Establish and develop technical marketing objectives and goals | Analyze and interpret marketing trends concerning technical products or services | . | . Professional Certification . Machine Learning from Stanford University Online. Oct/2018 | Mathematics for Machine Learning: Linear Algebra, from Imperial College London. Feb/2019 | Mathematics for Machine Learning: Multivariate Calculus, from from Imperial College London. Mar/2019 | Neural Network and Deep Learning, from deeplearning.ai. Mar/2019 | Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization, from deeplearning.ai. Apr/2019 | Convolutional Neural Networks, from deeplearning.ai. May/2019 | Sequance Models, from deeplearning.ai. Jul/2019 | . Education Background . National University of Singapore . Master of Science - MS, Technology &amp; Intelligent System . Machine Reasoning | Reasoning Systems | Cognitive Systems | Problem Solving using Pattern Recognition | Intelligent Sensing and Sense Making | Pattern Recognition and Machine Learning Systems | Text Analytics | New Media and Sentiment Mining | Text Processing using Machine Learning | Conversational UIs | Vision Systems | Spatial Reasoning from Sensor Data | Real Time Audio-Visual Sensing and Sense Making | . Royal Holloway, University of London . Bachelor of Science (B.S.), Marketing/Marketing Management, General . MN2041K Managerial Accounting | MN2061K Marketing Management | MN2155K Asia Pacific Businesses | MN2165K The Global Economy | MN22201K Strategic Management | MN3215K Asia Pacific Multinationals in Europe | MN3455K Advertising And Promotion in Brand Marketing | MN3495K Clusters, Small Business and International Competition | MN3555K E-Commerce | MN3035K Marketing Research | MN3055K Consumer Behaviour | MN3301K Modern Business in Comparative Perspective | . Guangzhou Civil Aviation College . Associate’s degree, Electrical and Electronics Engineering . Further Mathematics | College English | Circuit Analysis | Analog Electronic Technology | Digital Electronic Technology | Single-chip Microcomputer Design &amp; Develop | The C Programming Language | Computer Network | Digital Communication Theory | Stored Program Control &amp; Mobile Communication Theory | .",
          "url": "https://jl1829.github.io/turbo-funicular/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jl1829.github.io/turbo-funicular/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}